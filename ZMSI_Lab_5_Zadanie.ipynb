{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBXxErK07vQA"
   },
   "source": [
    "<center>\n",
    "    <font size=\"5\"> Zaawansowane Metody Uczenia Maszynowego i Głębokiegio<br/>\n",
    "        <small><em>Studia stacjonarne II stopnia 2024/2025</em><br/>Kierunek: Informatyka<br>Specjalność: Systemy inteligentne i rozszerzona rzeczywistość</small>\n",
    "    </font>\n",
    "</center>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWaTBVeDKX_7"
   },
   "source": [
    "# Laboratorium nr 5: Konwolucyjne sieci neuronowe: Zadanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wwk604uKLAFL"
   },
   "source": [
    "## Montowanie Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVD36wuwLBXw",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# uaktualnij poniższą ścieżkę\n",
    "path_nb = r'/content/drive/My Drive/Colab Notebooks/ZMUMiG_2024_25/'\n",
    "sys.path.append(path_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80MLD8g9BLgo"
   },
   "source": [
    "## Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nch5dQKB6gPb",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "print('Numpy version:', np.__version__)\n",
    "print('Tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_3efa9pLghG"
   },
   "source": [
    "## Zadanie\n",
    "\n",
    "Stwórz i wytrenuj głęboką konwolucyjną sieć neuronową zdolną poprawnie sklasyfikować zdjęcia pochodzące z fragmentu bazy CIFAR-100 (25 losowych klas).\n",
    "\n",
    "W trakcie realizacji zadania należy wykonań następujące podzadania:\n",
    "1. Wygenerować dane uczące i testowe (gotowy kod).\n",
    "2. Zdefiniować model głebokiej konwolucyjnej sieci neuronowej według własnego pomysłu.\n",
    "3. Wytrenować zdefiniowaną sieć na danych uczących z wyodrębnieniem zbioru walidacyjnego. W procesie uczenia wykorzystać powielanie danych uczących (data augmentation, https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)\n",
    "4. Ocenić skuteczność modelu na danych testowych.\n",
    "5. Powtarzać etapy 2-4 aż do osiągnięcia zadowalających wyników.\n",
    "6. Przeanalizować działanie stworzonej sieci, zestawienie jakie błedy w jakich klasach, zwizualizować wytrenowane filtry i mapy cech.\n",
    "\n",
    "\n",
    "### Baza CIFAR-100\n",
    "- Każdemu przydzielony zostaje fragment bazy CIFAR-100 zawierający dane uczące i testowe obrazów pochodzących z 25 klas.\n",
    "-Klasy wybierane są losowane w zależności od `nr_albumu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gSVhfLrL8A_"
   },
   "outputs": [],
   "source": [
    "# podaj swoj nr albumu\n",
    "nr_albumu = 111111\n",
    "\n",
    "np.random.seed(nr_albumu)\n",
    "(train_images_all, train_labels_all), (test_images_all, test_labels_all) = tf.keras.datasets.cifar100.load_data()\n",
    "my_classes = np.random.choice(range(100), size=25, replace=False)\n",
    "np.random.seed()\n",
    "\n",
    "mask = train_labels_all[:,0]==my_classes[0]\n",
    "mask2 = test_labels_all[:,0]==my_classes[0]\n",
    "train_images = train_images_all[mask]\n",
    "train_labels = np.ones(shape=(mask.sum(),1))*0\n",
    "test_images = test_images_all[mask2]\n",
    "test_labels = np.ones(shape=(mask2.sum(),1))*0\n",
    "for i, cl in enumerate(my_classes[1:]):\n",
    "  mask = train_labels_all[:,0]==cl\n",
    "  train_images = np.concatenate((train_images, train_images_all[mask]))\n",
    "  train_labels = np.concatenate((train_labels, np.ones(shape=(mask.sum(),1))*(i+1)))\n",
    "  mask2 = test_labels_all[:,0]==cl\n",
    "  test_images = np.concatenate((test_images, test_images_all[mask2]))\n",
    "  test_labels = np.concatenate((test_labels, np.ones(shape=(mask2.sum(),1))*(i+1)))\n",
    "\n",
    "print('Wylosowane klasy:')\n",
    "print(my_classes)\n",
    "print('Odpowiadające im nowe etykiety:')\n",
    "print(np.array(range(25)))\n",
    "\n",
    "# mieszanie danych\n",
    "indx = np.arange(0, train_images.shape[0], 1, dtype=np.int32)\n",
    "np.random.shuffle(indx)\n",
    "train_images = train_images[indx]\n",
    "train_labels = train_labels[indx]\n",
    "indx = np.arange(0, test_images.shape[0], 1, dtype=np.int32)\n",
    "np.random.shuffle(indx)\n",
    "test_images = test_images[indx]\n",
    "test_labels = test_labels[indx]\n",
    "\n",
    "# normalizacja\n",
    "train_images = train_images/255.\n",
    "train_labels = np.int64(train_labels)\n",
    "test_images = test_images/255.\n",
    "test_labels = np.int64(test_labels)\n",
    "print('Wymiary danych:')\n",
    "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSR-FMdH8VTk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
